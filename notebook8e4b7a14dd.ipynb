{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Cancer detection with Pytorch\n","\n","The aim of this project is to create an algorithm using deep learning and computer vision to identify metastatic cancer in small image patches taken from larger digital pathology scans. The GitHub repository for the project is the following: https://github.com/tanh3ka/tanh3ka-Master-of-Science-in-Data-Science-5511\n","\n","The data is from the Kaggle competition \"Histopathologic Cancer Detection\" (https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview)."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-05T09:02:58.654247Z","iopub.status.busy":"2023-06-05T09:02:58.652976Z","iopub.status.idle":"2023-06-05T09:03:12.302955Z","shell.execute_reply":"2023-06-05T09:03:12.301469Z","shell.execute_reply.started":"2023-06-05T09:02:58.654202Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader,Dataset, random_split\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import time \n","from PIL import Image\n","train_on_gpu = True\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n","\n","!pip install torchsummary\n","from torchsummary import summary\n","\n","import copy\n","\n","torch.manual_seed(0)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:04:19.024053Z","iopub.status.busy":"2023-06-05T09:04:19.023536Z","iopub.status.idle":"2023-06-05T09:04:19.321022Z","shell.execute_reply":"2023-06-05T09:04:19.319975Z","shell.execute_reply.started":"2023-06-05T09:04:19.024009Z"},"trusted":true},"outputs":[],"source":["path2labels = \"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\"\n","labels_df = pd.read_csv(path2labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:04:29.616520Z","iopub.status.busy":"2023-06-05T09:04:29.615856Z","iopub.status.idle":"2023-06-05T09:04:29.638104Z","shell.execute_reply":"2023-06-05T09:04:29.636670Z","shell.execute_reply.started":"2023-06-05T09:04:29.616468Z"},"trusted":true},"outputs":[],"source":["labels_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:04:51.346299Z","iopub.status.busy":"2023-06-05T09:04:51.345862Z","iopub.status.idle":"2023-06-05T09:04:51.357344Z","shell.execute_reply":"2023-06-05T09:04:51.356180Z","shell.execute_reply.started":"2023-06-05T09:04:51.346265Z"},"trusted":true},"outputs":[],"source":["labels_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:09:52.668348Z","iopub.status.busy":"2023-06-05T09:09:52.667882Z","iopub.status.idle":"2023-06-05T09:09:52.682517Z","shell.execute_reply":"2023-06-05T09:09:52.681180Z","shell.execute_reply.started":"2023-06-05T09:09:52.668316Z"},"trusted":true},"outputs":[],"source":["labels_df['label'].value_counts()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The dataset contains 220025 images, of which 89117 are malignant images."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:10:07.515397Z","iopub.status.busy":"2023-06-05T09:10:07.514919Z","iopub.status.idle":"2023-06-05T09:10:07.648600Z","shell.execute_reply":"2023-06-05T09:10:07.647346Z","shell.execute_reply.started":"2023-06-05T09:10:07.515359Z"},"trusted":true},"outputs":[],"source":["print(f'The dataset has {sum(labels_df.duplicated())} duplicates')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:10:15.819763Z","iopub.status.busy":"2023-06-05T09:10:15.819325Z","iopub.status.idle":"2023-06-05T09:10:21.041653Z","shell.execute_reply":"2023-06-05T09:10:21.040384Z","shell.execute_reply.started":"2023-06-05T09:10:15.819731Z"},"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(25, 4))\n","path2data = \"/kaggle/input/histopathologic-cancer-detection/train\"\n","train_imgs = os.listdir(path2data)\n","for idx, img in enumerate(np.random.choice(train_imgs, 20)):\n","    ax = fig.add_subplot(2, 20//2, idx+1)\n","    im = Image.open(path2data + \"/\" + img)\n","    plt.imshow(im)\n","    lab = labels_df.loc[labels_df[\"id\"] == img.split('.')[0], 'label'].values[0]\n","    ax.set_title(f'Label: {lab}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Data preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:10:29.136122Z","iopub.status.busy":"2023-06-05T09:10:29.135692Z","iopub.status.idle":"2023-06-05T09:10:29.147315Z","shell.execute_reply":"2023-06-05T09:10:29.145919Z","shell.execute_reply.started":"2023-06-05T09:10:29.136092Z"},"trusted":true},"outputs":[],"source":["class cancer_dataset(Dataset):\n","    def __init__(self, data_dir, transform, data_type=\"train\"):\n","        # path to images\n","        path2data = os.path.join(data_dir, data_type)\n","        \n","        # list of images in directory\n","        filenames = os.listdir(path2data)\n","        \n","        # get full path to images\n","        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n","        \n","        # get labels\n","        path2labels = os.path.join(data_dir, \"train_labels.csv\")\n","        labels_df = pd.read_csv(path2labels)\n","        \n","        # seg dataframe index to id\n","        labels_df.set_index(\"id\", inplace=True)\n","        \n","        # obtain labels from df\n","        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n","        \n","        self.transform = transform\n","        \n","        \n","    def __len__(self):\n","        # return size of dataset\n","        return len(self.full_filenames)\n","    \n","    def __getitem__(self, idx):\n","        # open image, apply transforms and return with label\n","        img = Image.open(self.full_filenames[idx]) # PIL image\n","        img = self.transform(img)\n","        return img, self.labels[idx]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Create transformers to convert PIL image to PyTorch tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:10:35.403009Z","iopub.status.busy":"2023-06-05T09:10:35.402491Z","iopub.status.idle":"2023-06-05T09:10:35.409928Z","shell.execute_reply":"2023-06-05T09:10:35.408545Z","shell.execute_reply.started":"2023-06-05T09:10:35.402871Z"},"trusted":true},"outputs":[],"source":["data_transformer = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Resize((46,46))])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:10:40.891540Z","iopub.status.busy":"2023-06-05T09:10:40.891051Z","iopub.status.idle":"2023-06-05T09:10:53.503142Z","shell.execute_reply":"2023-06-05T09:10:53.502056Z","shell.execute_reply.started":"2023-06-05T09:10:40.891500Z"},"trusted":true},"outputs":[],"source":["data_dir = \"/kaggle/input/histopathologic-cancer-detection\"\n","img_dataset = cancer_dataset(data_dir, data_transformer, \"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:14.177724Z","iopub.status.busy":"2023-06-05T09:11:14.176316Z","iopub.status.idle":"2023-06-05T09:11:14.341619Z","shell.execute_reply":"2023-06-05T09:11:14.340306Z","shell.execute_reply.started":"2023-06-05T09:11:14.177683Z"},"trusted":true},"outputs":[],"source":["img, label = img_dataset[19]\n","print(img.shape, torch.min(img), torch.max(img))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Data split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:22.293630Z","iopub.status.busy":"2023-06-05T09:11:22.292673Z","iopub.status.idle":"2023-06-05T09:11:22.327426Z","shell.execute_reply":"2023-06-05T09:11:22.325973Z","shell.execute_reply.started":"2023-06-05T09:11:22.293591Z"},"trusted":true},"outputs":[],"source":["len_dataset = len(img_dataset)\n","len_train = int(0.8 * len_dataset)\n","len_val = len_dataset - len_train\n","\n","train_ds, val_ds = random_split(img_dataset, [len_train, len_val])\n","\n","print(f'train dataset length: {len(train_ds)}')\n","print(f'validation dataset length: {len(val_ds)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:28.084820Z","iopub.status.busy":"2023-06-05T09:11:28.084269Z","iopub.status.idle":"2023-06-05T09:11:28.148999Z","shell.execute_reply":"2023-06-05T09:11:28.148161Z","shell.execute_reply.started":"2023-06-05T09:11:28.084773Z"},"trusted":true},"outputs":[],"source":["i = 0\n","for x, y in train_ds:\n","    print(x.shape, y)\n","    i += 1\n","    if i > 5:\n","        break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Transform image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:37.932415Z","iopub.status.busy":"2023-06-05T09:11:37.932008Z","iopub.status.idle":"2023-06-05T09:11:37.941088Z","shell.execute_reply":"2023-06-05T09:11:37.939884Z","shell.execute_reply.started":"2023-06-05T09:11:37.932383Z"},"trusted":true},"outputs":[],"source":["# transformer for trainging dataset\n","train_transf = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomRotation(45),\n","    transforms.RandomResizedCrop(96, scale=(0.8, 1.0), ratio=(1.0, 1.0)),\n","#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    transforms.ToTensor()\n","    ])\n","\n","# No augmentation for validation dataset\n","val_transf = transforms.Compose([\n","#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    transforms.ToTensor()\n","    ])\n","\n","# Overwrite the transforms functions\n","train_ds.transform = train_transf\n","val_ds.transform = val_transf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:43.512063Z","iopub.status.busy":"2023-06-05T09:11:43.511605Z","iopub.status.idle":"2023-06-05T09:11:43.520019Z","shell.execute_reply":"2023-06-05T09:11:43.518301Z","shell.execute_reply.started":"2023-06-05T09:11:43.512026Z"},"trusted":true},"outputs":[],"source":["train_ds.transform"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Create dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:11:51.814196Z","iopub.status.busy":"2023-06-05T09:11:51.813792Z","iopub.status.idle":"2023-06-05T09:11:52.228785Z","shell.execute_reply":"2023-06-05T09:11:52.227549Z","shell.execute_reply.started":"2023-06-05T09:11:51.814167Z"},"trusted":true},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n","val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)\n","\n","# check batches\n","for x, y in train_dl:\n","    print(x.shape)\n","    print(y.shape)\n","    break\n","    \n","for x, y in val_dl:\n","    print(x.shape)\n","    print(y.shape)\n","    break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:12:07.121825Z","iopub.status.busy":"2023-06-05T09:12:07.121358Z","iopub.status.idle":"2023-06-05T09:12:07.251802Z","shell.execute_reply":"2023-06-05T09:12:07.250527Z","shell.execute_reply.started":"2023-06-05T09:12:07.121791Z"},"trusted":true},"outputs":[],"source":["class Network(nn.Module):\n","    \n","    def __init__(self):\n","        \n","        super(Network, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=3)\n","        \n","        self.dropout_rate = 0.25\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(1*1*64, 100)\n","        self.fc2 = nn.Linear(100, 2)\n","        \n","    def forward(self, X):\n","        \n","        x = self.pool(F.relu(self.conv1(X)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.pool(F.relu(self.conv4(x)))\n","        # flatten\n","        x = x.view(-1, 1*1*64)\n","        \n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, self.dropout_rate)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","    \n","    \n","# create instant of model\n","cnn_model = Network()\n","\n","# define hardware\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = cnn_model.to(device)\n","print(device)\n","\n","summary(cnn_model, input_size=(3, 46, 46), device=device.type)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:12:15.431777Z","iopub.status.busy":"2023-06-05T09:12:15.431322Z","iopub.status.idle":"2023-06-05T09:12:16.066060Z","shell.execute_reply":"2023-06-05T09:12:16.064175Z","shell.execute_reply.started":"2023-06-05T09:12:15.431744Z"},"trusted":true},"outputs":[],"source":["m =torchvision.models.resnet50()\n","m.fc = nn.Linear(2048 , 2)\n","cnn_model = m\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = cnn_model.to(device)\n","print(device)\n","\n","summary(cnn_model, input_size=(3, 46, 46), device=device.type)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:12:26.885754Z","iopub.status.busy":"2023-06-05T09:12:26.885311Z","iopub.status.idle":"2023-06-05T09:12:26.891667Z","shell.execute_reply":"2023-06-05T09:12:26.890460Z","shell.execute_reply.started":"2023-06-05T09:12:26.885723Z"},"trusted":true},"outputs":[],"source":["loss_func = nn.NLLLoss(reduction=\"sum\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optimiser"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:12:37.437383Z","iopub.status.busy":"2023-06-05T09:12:37.436960Z","iopub.status.idle":"2023-06-05T09:12:37.445438Z","shell.execute_reply":"2023-06-05T09:12:37.443872Z","shell.execute_reply.started":"2023-06-05T09:12:37.437354Z"},"trusted":true},"outputs":[],"source":["opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n","lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=20, verbose=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:12:49.370486Z","iopub.status.busy":"2023-06-05T09:12:49.370036Z","iopub.status.idle":"2023-06-05T09:12:49.382962Z","shell.execute_reply":"2023-06-05T09:12:49.381902Z","shell.execute_reply.started":"2023-06-05T09:12:49.370438Z"},"trusted":true},"outputs":[],"source":["# Function to get the learning rate\n","def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']\n","\n","# Function to compute the loss value per batch of data\n","def loss_batch(loss_func, output, target, opt=None):\n","    \n","    loss = loss_func(output, target) # get loss\n","    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n","    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n","    \n","    if opt is not None:\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","    return loss.item(), metric_b\n","\n","# Compute the loss value & performance metric for the entire dataset (epoch)\n","def loss_epoch(model,loss_func,dataset_dl,opt=None):\n","    \n","    run_loss=0.0 \n","    t_metric=0.0\n","    len_data=len(dataset_dl.dataset)\n","\n","    # internal loop over dataset\n","    for xb, yb in tqdm(dataset_dl, leave=False):\n","        # move batch to device\n","        xb=xb.to(device)\n","        yb=yb.to(device)\n","        output=model(xb) # get model output\n","        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n","        run_loss+=loss_b        # update running loss\n","\n","        if metric_b is not None: # update running metric\n","            t_metric+=metric_b    \n","    \n","    loss=run_loss/float(len_data)  # average loss value\n","    metric=t_metric/float(len_data) # average metric value\n","    \n","    return loss, metric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:13:01.851816Z","iopub.status.busy":"2023-06-05T09:13:01.851271Z","iopub.status.idle":"2023-06-05T09:13:01.985491Z","shell.execute_reply":"2023-06-05T09:13:01.984386Z","shell.execute_reply.started":"2023-06-05T09:13:01.851780Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import trange, tqdm\n","\n","def train_val(model, params, verbose=False):\n","    \n","    # Get parameters\n","    epochs = params[\"epochs\"]\n","    opt = params[\"optimiser\"]\n","    loss_func = params[\"f_loss\"]\n","    train_dl = params[\"train\"]\n","    val_dl = params[\"val\"]\n","    lr_scheduler = params[\"lr_change\"]\n","    weight_path = params[\"weight_path\"]\n","    \n","    # history of loss and metric values in each epoch\n","    loss_history = {\"train\": [], \"val\": []}\n","    metric_history = {\"train\": [], \"val\": []}\n","    \n","    # a deep copy of weights for the best model\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    \n","    best_loss = float('inf')      # init loss\n","    \n","    # Train loop\n","    for epoch in tqdm(range(epochs), leave=False):\n","        \n","        # get lr\n","        current_lr = get_lr(opt)\n","        if(verbose):\n","            print(f'Epoch {epoch +1}/{epochs}, current lr={current_lr}')\n","        \n","        # train model\n","        model.train()\n","        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n","        \n","        loss_history[\"train\"].append(train_loss)\n","        metric_history[\"train\"].append(train_metric)\n","        \n","        # evaluate model\n","        model.eval()\n","        with torch.no_grad():\n","            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n","        \n","        # store best model\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            \n","            # save weights in a local file\n","            torch.save(model.state_dict(), weight_path)\n","            if verbose:\n","                print(\"Saved best model weights\")\n","            \n","        loss_history[\"val\"].append(val_loss)\n","        metric_history[\"val\"].append(val_metric)\n","        \n","        # lr schedule\n","        lr_scheduler.step(val_loss)\n","        if current_lr != get_lr(opt):\n","            if verbose:\n","                print(\"Loading best model weights\")\n","            model.load_state_dict(best_model_wts)\n","            \n","        if verbose:\n","            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n","            print(\"-\"*20)\n","            \n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, loss_history, metric_history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-05T09:13:09.195210Z","iopub.status.busy":"2023-06-05T09:13:09.194761Z"},"trusted":true},"outputs":[],"source":["params_train={\n"," \"train\": train_dl,\"val\": val_dl,\n"," \"epochs\": 10,\n"," \"optimiser\": opt,\n"," \"lr_change\": lr_scheduler,\n"," \"f_loss\": loss_func,\n"," \"weight_path\": \"weights.pt\",\n","}\n","\n","# Train model\n","\n","model, loss_hist, metric_hist = train_val(model, params_train, verbose=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Loss and Metrics visual"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import seaborn as sns; sns.set(style='whitegrid')\n","\n","epochs=params_train[\"epochs\"]\n","\n","fig,ax = plt.subplots(1,2,figsize=(12,5))\n","\n","sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n","sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n","sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='metric_hist[\"train\"]')\n","sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='metric_hist[\"val\"]')\n","plt.title('Convergence History')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Classify the test dataset with trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class cancerdata_test(Dataset):\n","    \n","    def __init__(self, data_dir, transform,data_type=\"train\"):\n","        \n","        path2data = os.path.join(data_dir,data_type)\n","        filenames = os.listdir(path2data)\n","        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n","        \n","        # labels are in a csv file named train_labels.csv\n","        csv_filename=\"sample_submission.csv\"\n","        path2csvLabels=os.path.join(data_dir,csv_filename)\n","        labels_df=pd.read_csv(path2csvLabels)\n","        \n","        # set data frame index to id\n","        labels_df.set_index(\"id\", inplace=True)\n","        \n","        # obtain labels from data frame\n","        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n","        self.transform = transform       \n","        \n","    def __len__(self):\n","        # return size of dataset\n","        return len(self.full_filenames)\n","    \n","    def __getitem__(self, idx):\n","        # open image, apply transforms and return with label\n","        image = Image.open(self.full_filenames[idx]) # PIL image\n","        image = self.transform(image)\n","        return image, self.labels[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load any model weights for the model\n","model.load_state_dict(torch.load('weights.pt'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path2sub = \"/kaggle/input/histopathologic-cancer-detection/sample_submission.csv\"\n","labels_df = pd.read_csv(path2sub)\n","data_dir = '/kaggle/input/histopathologic-cancer-detection/'\n","\n","data_transformer = transforms.Compose([transforms.ToTensor(),\n","                                       transforms.Resize((46,46))])\n","\n","img_dataset_test = cancerdata_test(data_dir,data_transformer,data_type=\"test\")\n","print(len(img_dataset_test), 'samples found')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def inference(model,dataset,device,num_classes=2):\n","    \n","    len_data=len(dataset)\n","    y_out=torch.zeros(len_data,num_classes) # initialize output tensor on CPU\n","    y_gt=np.zeros((len_data),dtype=\"uint8\") # initialize ground truth on CPU\n","    model=model.to(device) # move model to device\n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for i in tqdm(range(len_data)):\n","            x,y=dataset[i]\n","            y_gt[i]=y\n","            y_out[i]=model(x.unsqueeze(0).to(device))\n","\n","    return y_out.numpy(),y_gt           \n","\n","y_test_out,_ = inference(model,img_dataset_test, device)  \n","y_test_pred=np.argmax(y_test_out,axis=1)\n","\n","test_ids = [name.split('/')[-1].split('.')[0] for name in img_dataset_test.full_filenames]\n","test_preds = pd.DataFrame({\"img\": test_ids, \"preds\": y_test_pred})\n","submission = pd.merge(labels_df, test_preds, left_on='id', right_on='img')\n","submission = submission[['id', 'preds']]\n","submission.columns = ['id', 'label']\n","submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
