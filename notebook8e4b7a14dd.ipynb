{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset, random_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time \nfrom PIL import Image\ntrain_on_gpu = True\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\n!pip install torchsummary\nfrom torchsummary import summary\n\nimport copy\n\ntorch.manual_seed(0)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-05T09:02:58.652976Z","iopub.execute_input":"2023-06-05T09:02:58.654247Z","iopub.status.idle":"2023-06-05T09:03:12.302955Z","shell.execute_reply.started":"2023-06-05T09:02:58.654202Z","shell.execute_reply":"2023-06-05T09:03:12.301469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"path2labels = \"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\"\nlabels_df = pd.read_csv(path2labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:04:19.023536Z","iopub.execute_input":"2023-06-05T09:04:19.024053Z","iopub.status.idle":"2023-06-05T09:04:19.321022Z","shell.execute_reply.started":"2023-06-05T09:04:19.024009Z","shell.execute_reply":"2023-06-05T09:04:19.319975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"labels_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:04:29.615856Z","iopub.execute_input":"2023-06-05T09:04:29.616520Z","iopub.status.idle":"2023-06-05T09:04:29.638104Z","shell.execute_reply.started":"2023-06-05T09:04:29.616468Z","shell.execute_reply":"2023-06-05T09:04:29.636670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:04:51.345862Z","iopub.execute_input":"2023-06-05T09:04:51.346299Z","iopub.status.idle":"2023-06-05T09:04:51.357344Z","shell.execute_reply.started":"2023-06-05T09:04:51.346265Z","shell.execute_reply":"2023-06-05T09:04:51.356180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:09:52.667882Z","iopub.execute_input":"2023-06-05T09:09:52.668348Z","iopub.status.idle":"2023-06-05T09:09:52.682517Z","shell.execute_reply.started":"2023-06-05T09:09:52.668316Z","shell.execute_reply":"2023-06-05T09:09:52.681180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains 220025 images, of which 89117 are malignant images.","metadata":{}},{"cell_type":"code","source":"print(f'The dataset has {sum(labels_df.duplicated())} duplicates')","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:10:07.514919Z","iopub.execute_input":"2023-06-05T09:10:07.515397Z","iopub.status.idle":"2023-06-05T09:10:07.648600Z","shell.execute_reply.started":"2023-06-05T09:10:07.515359Z","shell.execute_reply":"2023-06-05T09:10:07.647346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(25, 4))\npath2data = \"/kaggle/input/histopathologic-cancer-detection/train\"\ntrain_imgs = os.listdir(path2data)\nfor idx, img in enumerate(np.random.choice(train_imgs, 20)):\n    ax = fig.add_subplot(2, 20//2, idx+1)\n    im = Image.open(path2data + \"/\" + img)\n    plt.imshow(im)\n    lab = labels_df.loc[labels_df[\"id\"] == img.split('.')[0], 'label'].values[0]\n    ax.set_title(f'Label: {lab}')","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:10:15.819325Z","iopub.execute_input":"2023-06-05T09:10:15.819763Z","iopub.status.idle":"2023-06-05T09:10:21.041653Z","shell.execute_reply.started":"2023-06-05T09:10:15.819731Z","shell.execute_reply":"2023-06-05T09:10:21.040384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocess","metadata":{}},{"cell_type":"code","source":"class cancer_dataset(Dataset):\n    def __init__(self, data_dir, transform, data_type=\"train\"):\n        # path to images\n        path2data = os.path.join(data_dir, data_type)\n        \n        # list of images in directory\n        filenames = os.listdir(path2data)\n        \n        # get full path to images\n        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n        \n        # get labels\n        path2labels = os.path.join(data_dir, \"train_labels.csv\")\n        labels_df = pd.read_csv(path2labels)\n        \n        # seg dataframe index to id\n        labels_df.set_index(\"id\", inplace=True)\n        \n        # obtain labels from df\n        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n        \n        self.transform = transform\n        \n        \n    def __len__(self):\n        # return size of dataset\n        return len(self.full_filenames)\n    \n    def __getitem__(self, idx):\n        # open image, apply transforms and return with label\n        img = Image.open(self.full_filenames[idx]) # PIL image\n        img = self.transform(img)\n        return img, self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:10:29.135692Z","iopub.execute_input":"2023-06-05T09:10:29.136122Z","iopub.status.idle":"2023-06-05T09:10:29.147315Z","shell.execute_reply.started":"2023-06-05T09:10:29.136092Z","shell.execute_reply":"2023-06-05T09:10:29.145919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create transformers to convert PIL image to PyTorch tensors","metadata":{}},{"cell_type":"code","source":"data_transformer = transforms.Compose([transforms.ToTensor(),\n                                       transforms.Resize((46,46))])","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:10:35.402491Z","iopub.execute_input":"2023-06-05T09:10:35.403009Z","iopub.status.idle":"2023-06-05T09:10:35.409928Z","shell.execute_reply.started":"2023-06-05T09:10:35.402871Z","shell.execute_reply":"2023-06-05T09:10:35.408545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/histopathologic-cancer-detection\"\nimg_dataset = cancer_dataset(data_dir, data_transformer, \"train\")","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:10:40.891051Z","iopub.execute_input":"2023-06-05T09:10:40.891540Z","iopub.status.idle":"2023-06-05T09:10:53.503142Z","shell.execute_reply.started":"2023-06-05T09:10:40.891500Z","shell.execute_reply":"2023-06-05T09:10:53.502056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = img_dataset[19]\nprint(img.shape, torch.min(img), torch.max(img))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:14.176316Z","iopub.execute_input":"2023-06-05T09:11:14.177724Z","iopub.status.idle":"2023-06-05T09:11:14.341619Z","shell.execute_reply.started":"2023-06-05T09:11:14.177683Z","shell.execute_reply":"2023-06-05T09:11:14.340306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data split","metadata":{}},{"cell_type":"code","source":"len_dataset = len(img_dataset)\nlen_train = int(0.8 * len_dataset)\nlen_val = len_dataset - len_train\n\ntrain_ds, val_ds = random_split(img_dataset, [len_train, len_val])\n\nprint(f'train dataset length: {len(train_ds)}')\nprint(f'validation dataset length: {len(val_ds)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:22.292673Z","iopub.execute_input":"2023-06-05T09:11:22.293630Z","iopub.status.idle":"2023-06-05T09:11:22.327426Z","shell.execute_reply.started":"2023-06-05T09:11:22.293591Z","shell.execute_reply":"2023-06-05T09:11:22.325973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor x, y in train_ds:\n    print(x.shape, y)\n    i += 1\n    if i > 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:28.084269Z","iopub.execute_input":"2023-06-05T09:11:28.084820Z","iopub.status.idle":"2023-06-05T09:11:28.148999Z","shell.execute_reply.started":"2023-06-05T09:11:28.084773Z","shell.execute_reply":"2023-06-05T09:11:28.148161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform image","metadata":{}},{"cell_type":"code","source":"# transformer for trainging dataset\ntrain_transf = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(45),\n    transforms.RandomResizedCrop(96, scale=(0.8, 1.0), ratio=(1.0, 1.0)),\n#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    transforms.ToTensor()\n    ])\n\n# No augmentation for validation dataset\nval_transf = transforms.Compose([\n#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    transforms.ToTensor()\n    ])\n\n# Overwrite the transforms functions\ntrain_ds.transform = train_transf\nval_ds.transform = val_transf","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:37.932008Z","iopub.execute_input":"2023-06-05T09:11:37.932415Z","iopub.status.idle":"2023-06-05T09:11:37.941088Z","shell.execute_reply.started":"2023-06-05T09:11:37.932383Z","shell.execute_reply":"2023-06-05T09:11:37.939884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.transform","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:43.511605Z","iopub.execute_input":"2023-06-05T09:11:43.512063Z","iopub.status.idle":"2023-06-05T09:11:43.520019Z","shell.execute_reply.started":"2023-06-05T09:11:43.512026Z","shell.execute_reply":"2023-06-05T09:11:43.518301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloaders","metadata":{}},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=32, shuffle=False)\n\n# check batches\nfor x, y in train_dl:\n    print(x.shape)\n    print(y.shape)\n    break\n    \nfor x, y in val_dl:\n    print(x.shape)\n    print(y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:11:51.813792Z","iopub.execute_input":"2023-06-05T09:11:51.814196Z","iopub.status.idle":"2023-06-05T09:11:52.228785Z","shell.execute_reply.started":"2023-06-05T09:11:51.814167Z","shell.execute_reply":"2023-06-05T09:11:52.227549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN model","metadata":{}},{"cell_type":"code","source":"class Network(nn.Module):\n    \n    def __init__(self):\n        \n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(3, 8, kernel_size=3)\n        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n        self.conv3 = nn.Conv2d(16, 32, kernel_size=3)\n        self.conv4 = nn.Conv2d(32, 64, kernel_size=3)\n        \n        self.dropout_rate = 0.25\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(1*1*64, 100)\n        self.fc2 = nn.Linear(100, 2)\n        \n    def forward(self, X):\n        \n        x = self.pool(F.relu(self.conv1(X)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        # flatten\n        x = x.view(-1, 1*1*64)\n        \n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, self.dropout_rate)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n    \n    \n# create instant of model\ncnn_model = Network()\n\n# define hardware\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = cnn_model.to(device)\nprint(device)\n\nsummary(cnn_model, input_size=(3, 46, 46), device=device.type)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:12:07.121358Z","iopub.execute_input":"2023-06-05T09:12:07.121825Z","iopub.status.idle":"2023-06-05T09:12:07.251802Z","shell.execute_reply.started":"2023-06-05T09:12:07.121791Z","shell.execute_reply":"2023-06-05T09:12:07.250527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m =torchvision.models.resnet50()\nm.fc = nn.Linear(2048 , 2)\ncnn_model = m\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = cnn_model.to(device)\nprint(device)\n\nsummary(cnn_model, input_size=(3, 46, 46), device=device.type)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:12:15.431322Z","iopub.execute_input":"2023-06-05T09:12:15.431777Z","iopub.status.idle":"2023-06-05T09:12:16.066060Z","shell.execute_reply.started":"2023-06-05T09:12:15.431744Z","shell.execute_reply":"2023-06-05T09:12:16.064175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loss function","metadata":{}},{"cell_type":"code","source":"loss_func = nn.NLLLoss(reduction=\"sum\")","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:12:26.885311Z","iopub.execute_input":"2023-06-05T09:12:26.885754Z","iopub.status.idle":"2023-06-05T09:12:26.891667Z","shell.execute_reply.started":"2023-06-05T09:12:26.885723Z","shell.execute_reply":"2023-06-05T09:12:26.890460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optimiser","metadata":{}},{"cell_type":"code","source":"opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\nlr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=20, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:12:37.436960Z","iopub.execute_input":"2023-06-05T09:12:37.437383Z","iopub.status.idle":"2023-06-05T09:12:37.445438Z","shell.execute_reply.started":"2023-06-05T09:12:37.437354Z","shell.execute_reply":"2023-06-05T09:12:37.443872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Function to get the learning rate\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n\n# Function to compute the loss value per batch of data\ndef loss_batch(loss_func, output, target, opt=None):\n    \n    loss = loss_func(output, target) # get loss\n    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n    \n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    return loss.item(), metric_b\n\n# Compute the loss value & performance metric for the entire dataset (epoch)\ndef loss_epoch(model,loss_func,dataset_dl,opt=None):\n    \n    run_loss=0.0 \n    t_metric=0.0\n    len_data=len(dataset_dl.dataset)\n\n    # internal loop over dataset\n    for xb, yb in tqdm(dataset_dl, leave=False):\n        # move batch to device\n        xb=xb.to(device)\n        yb=yb.to(device)\n        output=model(xb) # get model output\n        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n        run_loss+=loss_b        # update running loss\n\n        if metric_b is not None: # update running metric\n            t_metric+=metric_b    \n    \n    loss=run_loss/float(len_data)  # average loss value\n    metric=t_metric/float(len_data) # average metric value\n    \n    return loss, metric","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:12:49.370036Z","iopub.execute_input":"2023-06-05T09:12:49.370486Z","iopub.status.idle":"2023-06-05T09:12:49.382962Z","shell.execute_reply.started":"2023-06-05T09:12:49.370438Z","shell.execute_reply":"2023-06-05T09:12:49.381902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import trange, tqdm\n\ndef train_val(model, params, verbose=False):\n    \n    # Get parameters\n    epochs = params[\"epochs\"]\n    opt = params[\"optimiser\"]\n    loss_func = params[\"f_loss\"]\n    train_dl = params[\"train\"]\n    val_dl = params[\"val\"]\n    lr_scheduler = params[\"lr_change\"]\n    weight_path = params[\"weight_path\"]\n    \n    # history of loss and metric values in each epoch\n    loss_history = {\"train\": [], \"val\": []}\n    metric_history = {\"train\": [], \"val\": []}\n    \n    # a deep copy of weights for the best model\n    best_model_wts = copy.deepcopy(model.state_dict())\n    \n    best_loss = float('inf')      # init loss\n    \n    # Train loop\n    for epoch in tqdm(range(epochs), leave=False):\n        \n        # get lr\n        current_lr = get_lr(opt)\n        if(verbose):\n            print(f'Epoch {epoch +1}/{epochs}, current lr={current_lr}')\n        \n        # train model\n        model.train()\n        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n        \n        loss_history[\"train\"].append(train_loss)\n        metric_history[\"train\"].append(train_metric)\n        \n        # evaluate model\n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n        \n        # store best model\n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            \n            # save weights in a local file\n            torch.save(model.state_dict(), weight_path)\n            if verbose:\n                print(\"Saved best model weights\")\n            \n        loss_history[\"val\"].append(val_loss)\n        metric_history[\"val\"].append(val_metric)\n        \n        # lr schedule\n        lr_scheduler.step(val_loss)\n        if current_lr != get_lr(opt):\n            if verbose:\n                print(\"Loading best model weights\")\n            model.load_state_dict(best_model_wts)\n            \n        if verbose:\n            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n            print(\"-\"*20)\n            \n    model.load_state_dict(best_model_wts)\n    \n    return model, loss_history, metric_history","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:13:01.851271Z","iopub.execute_input":"2023-06-05T09:13:01.851816Z","iopub.status.idle":"2023-06-05T09:13:01.985491Z","shell.execute_reply.started":"2023-06-05T09:13:01.851780Z","shell.execute_reply":"2023-06-05T09:13:01.984386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_train={\n \"train\": train_dl,\"val\": val_dl,\n \"epochs\": 10,\n \"optimiser\": opt,\n \"lr_change\": lr_scheduler,\n \"f_loss\": loss_func,\n \"weight_path\": \"weights.pt\",\n}\n\n# Train model\n\nmodel, loss_hist, metric_hist = train_val(model, params_train, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:13:09.194761Z","iopub.execute_input":"2023-06-05T09:13:09.195210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loss and Metrics visual","metadata":{}},{"cell_type":"code","source":"import seaborn as sns; sns.set(style='whitegrid')\n\nepochs=params_train[\"epochs\"]\n\nfig,ax = plt.subplots(1,2,figsize=(12,5))\n\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='metric_hist[\"train\"]')\nsns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='metric_hist[\"val\"]')\nplt.title('Convergence History')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classify the test dataset with trained model","metadata":{}},{"cell_type":"code","source":"class cancerdata_test(Dataset):\n    \n    def __init__(self, data_dir, transform,data_type=\"train\"):\n        \n        path2data = os.path.join(data_dir,data_type)\n        filenames = os.listdir(path2data)\n        self.full_filenames = [os.path.join(path2data, f) for f in filenames]\n        \n        # labels are in a csv file named train_labels.csv\n        csv_filename=\"sample_submission.csv\"\n        path2csvLabels=os.path.join(data_dir,csv_filename)\n        labels_df=pd.read_csv(path2csvLabels)\n        \n        # set data frame index to id\n        labels_df.set_index(\"id\", inplace=True)\n        \n        # obtain labels from data frame\n        self.labels = [labels_df.loc[filename[:-4]].values[0] for filename in filenames]\n        self.transform = transform       \n        \n    def __len__(self):\n        # return size of dataset\n        return len(self.full_filenames)\n    \n    def __getitem__(self, idx):\n        # open image, apply transforms and return with label\n        image = Image.open(self.full_filenames[idx]) # PIL image\n        image = self.transform(image)\n        return image, self.labels[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load any model weights for the model\nmodel.load_state_dict(torch.load('weights.pt'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path2sub = \"/kaggle/input/histopathologic-cancer-detection/sample_submission.csv\"\nlabels_df = pd.read_csv(path2sub)\ndata_dir = '/kaggle/input/histopathologic-cancer-detection/'\n\ndata_transformer = transforms.Compose([transforms.ToTensor(),\n                                       transforms.Resize((46,46))])\n\nimg_dataset_test = cancerdata_test(data_dir,data_transformer,data_type=\"test\")\nprint(len(img_dataset_test), 'samples found')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(model,dataset,device,num_classes=2):\n    \n    len_data=len(dataset)\n    y_out=torch.zeros(len_data,num_classes) # initialize output tensor on CPU\n    y_gt=np.zeros((len_data),dtype=\"uint8\") # initialize ground truth on CPU\n    model=model.to(device) # move model to device\n    model.eval()\n    \n    with torch.no_grad():\n        for i in tqdm(range(len_data)):\n            x,y=dataset[i]\n            y_gt[i]=y\n            y_out[i]=model(x.unsqueeze(0).to(device))\n\n    return y_out.numpy(),y_gt           \n\ny_test_out,_ = inference(model,img_dataset_test, device)  \ny_test_pred=np.argmax(y_test_out,axis=1)\n\ntest_ids = [name.split('/')[-1].split('.')[0] for name in img_dataset_test.full_filenames]\ntest_preds = pd.DataFrame({\"img\": test_ids, \"preds\": y_test_pred})\nsubmission = pd.merge(labels_df, test_preds, left_on='id', right_on='img')\nsubmission = submission[['id', 'preds']]\nsubmission.columns = ['id', 'label']\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}